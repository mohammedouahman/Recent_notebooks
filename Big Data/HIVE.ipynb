{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HIVE\n",
    "\n",
    "\n",
    "__HIVE__ is a data warehousing software that enables SQL like queries to extract data from Apache Hadoop. [link](https://www.talend.com/resources/what-is-apache-hive/)\n",
    "\n",
    "\n",
    "## How it Works.\n",
    "It translates HiveQL into a Java MapReduce/Spark job. (Uses YARN) HIVE organizes the data into tables, then runs the job on a cluster.\n",
    "\n",
    "Limitations of Hive:\n",
    "• Hive is not designed for Online transaction processing (OLTP ), it is only used for the Online Analytical Processing.\n",
    "\n",
    "• Hive supports overwriting or apprehending data, but not updates and deletes.\n",
    "\n",
    "• In Hive, sub queries are not supported.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show databases;\n",
    "use databasename;\n",
    "#copy data to HDFS\n",
    "hadoop dfs -copyFromLocal C://Desktop/data.txt hdfs:/ \n",
    "#create table in HIVE\n",
    "create table training_data(txnno INT, txdate STRING, custno INT, category STRING) row format delimited fields terminated by ',' stored as textfile;\n",
    "describe training_data;\n",
    "\n",
    "#load data into HIVE table\n",
    "load data inpath 'hdfs:/file.txt' OVERWRITE INTO TABLE training_data;\n",
    "\n",
    "select count(*) from training_data"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
