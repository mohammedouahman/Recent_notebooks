
For this project, I used a dataset for predicting income from socioeconomic variables (https://archive.ics.uci.edu/ml/datasets/Adult)

I removed most of the ordinal/categorical features, and created a few features of my own that combined subcategories of education into a binary variable.

The original tree achieved a test accuracy of 80%

The pruning algorithm iterated from the decision nodes closes to the leaves, up towards the root. At each decision node, the node was pruned, results were compared, and if the resulting accuracy did not decrease, the node was permanently removed. Otherwise the tree was restored to its state before the pruning.

The pruned model had an accuracy of 79% with significantly fewer decision nodes.
